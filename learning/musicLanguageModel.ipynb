{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current state-of-the-art ADT systems mainly focus on extracting the onset times of the drum events without taking into account the musical context. Specifically, most of the state-of-the-art systems are activation-based methods with a simple peak-picking process as the final step. While achieving decent results, these approaches do not benefit from high-level musical information. The integration of LMs (as mentioned in Sect.II-D) into ADT systems has been proposed in previous work [53]. However, results so far are below current systems without LMs. Furthermore, new types of LMs (e.g.,LSTMs) have not been tested for ADT. This is mainly due to the fact that the application of common LMs from the automatic speech recognition domain is not trivial, and large datasets for both audio and symbolic data for drums are not publicly available (as mentioned in Sect.II-D). Although the lack of large training datasets as well as the adaptation of ASR methods for music are a challenge, the integration of LMs in modern ADT approaches might be another direction that can potentially lead to a breakthrough in ADT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Identify what is the smallest time interval between notes in our dataset \n",
    "\"\"\"\n",
    "import os\n",
    "TracksLocations = \"/Users/mzehren/Programming/adtofParsed/midi_converted\"\n",
    "midis = [os.path.join(TracksLocations, path) for path in os.listdir(TracksLocations)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[  3.05732     3.05732     3.05732   ... 184.540977  184.7357815\n 184.930586 ]\n[ 13.429105    13.56929175  13.7094785  ... 313.57168025 313.7009905\n 313.7009905 ]\n"
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "\n",
    "for file in midis[:2]:\n",
    "    midi = pretty_midi.PrettyMIDI(file)\n",
    "    onsets = midi.get_onsets()\n",
    "    diff = [value for value in np.diff(onsets) if value != 0]\n",
    "    minimum = np.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitb13b9c22a2e24e549401f42f266a5d41",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}